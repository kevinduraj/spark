{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "// Databricks notebook source exported at Mon, 8 Feb 2016 23:29:54 UTC\n",
    "\n",
    "\n",
    "#![Wikipedia Logo](http://sameerf-dbc-labs.s3-website-us-west-2.amazonaws.com/data/wikipedia/images/w_logo_for_labs.png)\n",
    "\n",
    "# Explore English Wikipedia clickstream\n",
    "### Time to complete: 20 minutes\n",
    "\n",
    "#### Business Questions:\n",
    "\n",
    "* Question # 1) What are the top 10 articles requested from Wikipedia?\n",
    "* Question # 2) Who sent the most traffic to Wikipedia in Feb 2015?\n",
    "* Question # 3) What were the top 5 trending articles on Twitter in Feb 2015?\n",
    "* Question # 4) What are the most requested missing pages?\n",
    "* Question # 5) What does the traffic inflow vs outflow look like for the most requested pages?\n",
    "* Question # 6) What does the traffic flow pattern look like for the San Francisco article? Create a visualization for this.\n",
    "\n",
    "#### Technical Accomplishments:\n",
    "\n",
    "* Learn how to use the Spark CSV Library to read structured files\n",
    "* Explore the Spark UIs to understand the performance characteristics of your Spark jobs\n",
    "* Mix SQL and DataFrames queries\n",
    "* Join 2 DataFrames\n",
    "* Create a Google visualization to understand the clickstream traffic for the 'San Francisco' article\n",
    "* Bonus: Explain in DataFrames and SQL\n",
    "\n",
    "\n",
    "\n",
    "Dataset: http://datahub.io/dataset/wikipedia-clickstream/resource/be85cc68-d1e6-4134-804a-fd36b94dbb82\n",
    "\n",
    "Lab idea from [Ellery Wulczyn](https://ewulczyn.github.io/Wikipedia_Clickstream_Getting_Started/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The file we are exploring in this lab is the February 2015 English Wikipedia Clickstream data. \n",
    "\n",
    "According to Wikimedia: \n",
    "\n",
    ">\"The data contains counts of (referer, resource) pairs extracted from the request logs of English Wikipedia. When a client requests a resource by following a link or performing a search, the URI of the webpage that linked to the resource is included with the request in an HTTP header called the \"referer\". This data captures 22 million (referer, resource) pairs from a total of 3.2 billion requests collected during the month of February 2015.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DataFrames\n",
    "A `sqlContext` object is your entry point for working with structured data (rows and columns) in Spark.\n",
    "\n",
    "Let's use the `sqlContext` to read a table of the Clickstream data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import sqlContext.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@2d34a88a"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Notice that the sqlContext in DSE is actually a HiveContext\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " A `HiveContext` includes additional features like the ability to write queries using the more complete HiveQL parser, access to Hive UDFs, and the ability to read data from Hive tables. In general, you should always aim to use the `HiveContext` over the more limited `sqlContext`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " First let's load the data into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Use the [Spark CSV Library](https://github.com/databricks/spark-csv) to parse the tab separated file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "//Create a DataFrame with the anticipated structure\n",
    "val clickstreamDF = sqlContext.read.format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"delimiter\", \"\\t\")\n",
    "  .option(\"mode\", \"PERMISSIVE\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .load(\"file:///mnt/ephemeral/summitdata/2015_01_clickstream.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----+--------------------+----------+----+\n",
      "| prev_id|curr_id|   n|          prev_title|curr_title|type|\n",
      "+--------+-------+----+--------------------+----------+----+\n",
      "|    null|3632887| 415|         other-empty|        !!|null|\n",
      "|    null|3632887| 113|        other-google|        !!|null|\n",
      "|    null|3632887|  33|     other-wikipedia|        !!|null|\n",
      "|    null| 600744|  25|         other-yahoo|       !!!|null|\n",
      "|    null| 600744|1193|        other-google|       !!!|null|\n",
      "|    null| 600744|1065|         other-empty|       !!!|null|\n",
      "|25014178| 600744|  44|         Jerry_Fuchs|       !!!|null|\n",
      "|34552784| 600744|  11|   Flight_Facilities|       !!!|null|\n",
      "|    4499| 600744|  21|                Band|       !!!|null|\n",
      "| 1446971| 600744|  14|Gold_Standard_Lab...|       !!!|null|\n",
      "| 8526330| 600744|  70|          Myth_Takes|       !!!|null|\n",
      "| 1507641| 600744| 139|     LCD_Soundsystem|       !!!|null|\n",
      "| 2064029| 600744|  31|             Out_Hud|       !!!|null|\n",
      "|26780719| 600744|  40|List_of_post-punk...|       !!!|null|\n",
      "|39256216| 600744|  95|            Thr!!!er|       !!!|null|\n",
      "|11184232| 600744|  35|Tony_Hawk's_Provi...|       !!!|null|\n",
      "| 1327495| 600744|  11|     Sziget_Festival|       !!!|null|\n",
      "|  156725| 600744| 110| Warp_(record_label)|       !!!|null|\n",
      "|   29631| 600744|  14|Sacramento,_Calif...|       !!!|null|\n",
      "|    null| 600744| 136|               other|       !!!|null|\n",
      "+--------+-------+----+--------------------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " `printSchema()` prints out the schema, the data types and whether a column can be null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prev_id: integer (nullable = true)\n",
      " |-- curr_id: integer (nullable = true)\n",
      " |-- n: integer (nullable = true)\n",
      " |-- prev_title: string (nullable = true)\n",
      " |-- curr_title: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The two id columns (prev_id and curr_id) are not used in this lab, so let's create a new DataFrame without them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val clickstreamDF2 = clickstreamDF.select($\"prev_title\", $\"curr_title\", $\"n\", $\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----+----+\n",
      "|     prev_title|curr_title|   n|type|\n",
      "+---------------+----------+----+----+\n",
      "|    other-empty|        !!| 415|null|\n",
      "|   other-google|        !!| 113|null|\n",
      "|other-wikipedia|        !!|  33|null|\n",
      "|    other-yahoo|       !!!|  25|null|\n",
      "|   other-google|       !!!|1193|null|\n",
      "+---------------+----------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Here is what the 6 columns mean:\n",
    "\n",
    "- `prev_id`: *(note, we already dropped this)* if the referer does not correspond to an article in the main namespace of English Wikipedia, this value will be empty. Otherwise, it contains the unique MediaWiki page ID of the article corresponding to the referer i.e. the previous article the client was on\n",
    "\n",
    "- `curr_id`: *(note, we already dropped this)* the MediaWiki unique page ID of the article the client requested\n",
    "\n",
    "- `prev_title`: the result of mapping the referer URL to the fixed set of values described above\n",
    "\n",
    "- `curr_title`: the title of the article the client requested\n",
    "\n",
    "- `n`: the number of occurrences of the (referer, resource) pair\n",
    "\n",
    "- `type`\n",
    "  - \"link\" if the referer and request are both articles and the referer links to the request\n",
    "  - \"redlink\" if the referer is an article and links to the request, but the request is not in the production enwiki.page table\n",
    "  - \"other\" if the referer and request are both articles but the referer does not link to the request. This can happen when clients search or spoof their refer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Referers were mapped to a fixed set of values corresponding to internal traffic or external traffic from one of the top 5 global traffic sources to English Wikipedia, based on this scheme:\n",
    "\n",
    ">- an article in the main namespace of English Wikipedia -> the article title\n",
    "- any Wikipedia page that is not in the main namespace of English Wikipedia -> `other-wikipedia`\n",
    "- an empty referer -> `other-empty`\n",
    "- a page from any other Wikimedia project -> `other-internal`\n",
    "- Google -> `other-google`\n",
    "- Yahoo -> `other-yahoo`\n",
    "- Bing -> `other-bing`\n",
    "- Facebook -> `other-facebook`\n",
    "- Twitter -> `other-twitter`\n",
    "- anything else -> `other-other`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reading from disk vs memory\n",
    "\n",
    "The 1.2 GB Clickstream file is currently on S3, which means each time you scan through it, your Spark cluster has to read the 1.2 GB of data remotely over the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Call the `count()` action to check how many rows are in the DataFrame and to see how long it takes to read the DataFrame from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 21996601"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickstreamDF2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " So it took about 1 minute to read the 1.2 GB file into your Spark cluster. The file has 22.5 million rows/lines. We should cache the DataFrame into memory so it'll be faster to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 21996601"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cache() is a lazy operation, so we need to call an action (like count) to materialize the cache\n",
    "clickstreamDF2.cache().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " How much faster is the DataFrame to read from memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 21996601"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickstreamDF2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Less than a second!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Question #1:\n",
    "** What are the top 10 articles requested from Wikipedia?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " We start by grouping by the current title and summing the number of occurrences of the referrer/resource pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------------+------+\n",
      "|          curr_title|sum(n)|\n",
      "+--------------------+------+\n",
      "|     Arne_Hamarsland|    14|\n",
      "|      Arnold_Kramish|    39|\n",
      "|      Arnold_Mindell|   451|\n",
      "|Arnold_Williams_(...|    24|\n",
      "|Arnoldus_Andries_...|    36|\n",
      "|                Arod|   124|\n",
      "|             Arruazu|   166|\n",
      "|      Arsen_Minasian|    33|\n",
      "|            Artangel|   257|\n",
      "|      Arthroconidium|   465|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF2.groupBy(\"curr_title\").sum().limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " To see just the top 10 articles requested, we also need to order by the sum of n column, in descending order.\n",
    "\n",
    "** Challenge 1:** Can you build upon the code in the cell above to also order by the sum column in descending order, then limit the results to the top ten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------------+---------+\n",
      "|          curr_title|   sum(n)|\n",
      "+--------------------+---------+\n",
      "|           Main_Page|489603866|\n",
      "|          Chris_Kyle|  4211238|\n",
      "|             Malware|  4067814|\n",
      "|       Charlie_Hebdo|  2581856|\n",
      "|     Leptin_receptor|  2565856|\n",
      "|              Chrome|  1792151|\n",
      "|       Script_kiddie|  1779860|\n",
      "|American_Sniper_(...|  1753218|\n",
      "|Winston-Salem/For...|  1542559|\n",
      "|        Flow_control|  1369143|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Type in your answer here...\n",
    "clickstreamDF2.groupBy(\"curr_title\").sum().orderBy($\"sum(n)\".desc).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Spark SQL lets you seemlessly move between DataFrames and SQL. We can run the same query using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "//First register the table, so we can call it from SQL\n",
    "clickstreamDF2.registerTempTable(\"clickstream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " First do a simple \"Select all\" query from the `clickstream` table to make sure it's working:\n",
    " \n",
    " #### This is more like the way you would normally use sql in a real application  `%%sql` does something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[other-empty,!!,415,null]\n",
      "[other-google,!!,113,null]\n",
      "[other-wikipedia,!!,33,null]\n",
      "[other-yahoo,!!!,25,null]\n",
      "[other-google,!!!,1193,null]\n"
     ]
    }
   ],
   "source": [
    "val rows = sqlContext.sql(\"SELECT * FROM clickstream LIMIT 5\")\n",
    "rows.collect.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>prev_title</th><th>curr_title</th><th>n</th><th>type</th></tr><tr><td>other-empty</td><td>!!</td><td>415</td><td>null</td></tr><tr><td>other-google</td><td>!!</td><td>113</td><td>null</td></tr><tr><td>other-wikipedia</td><td>!!</td><td>33</td><td>null</td></tr><tr><td>other-yahoo</td><td>!!!</td><td>25</td><td>null</td></tr><tr><td>other-google</td><td>!!!</td><td>1193</td><td>null</td></tr></table>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql SELECT * FROM clickstream LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Now we can translate our DataFrames query to SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>curr_title</th><th>top_articles</th></tr><tr><td>Main_Page</td><td>489603866</td></tr><tr><td>Chris_Kyle</td><td>4211238</td></tr><tr><td>Malware</td><td>4067814</td></tr><tr><td>Charlie_Hebdo</td><td>2581856</td></tr><tr><td>Leptin_receptor</td><td>2565856</td></tr><tr><td>Chrome</td><td>1792151</td></tr><tr><td>Script_kiddie</td><td>1779860</td></tr><tr><td>American_Sniper_(film)</td><td>1753218</td></tr><tr><td>Winston-Salem/Forsyth_County_Schools</td><td>1542559</td></tr><tr><td>Flow_control</td><td>1369143</td></tr></table>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql SELECT curr_title, SUM(n) AS top_articles\n",
    "FROM clickstream GROUP BY curr_title\n",
    "ORDER BY top_articles DESC LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The most requested articles tend to be about media that was popular in February 2015, with a few exceptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " SQL also has some handy commands like `DESC` (describe) to see the schema + data types for the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>col_name</th><th>data_type</th><th>comment</th></tr><tr><td>prev_title</td><td>string</td><td></td></tr><tr><td>curr_title</td><td>string</td><td></td></tr><tr><td>n</td><td>int</td><td></td></tr><tr><td>type</td><td>string</td><td></td></tr></table>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql DESC clickstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " You can use the `SHOW FUNCTIONS` command to see what functions are supported by Spark SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>function</th></tr><tr><td>!</td></tr><tr><td>!=</td></tr><tr><td>%</td></tr><tr><td>&amp;</td></tr><tr><td>*</td></tr><tr><td>+</td></tr><tr><td>-</td></tr><tr><td>/</td></tr><tr><td>&lt;</td></tr><tr><td>&lt;=</td></tr><tr><td>&lt;=&gt;</td></tr><tr><td>&lt;&gt;</td></tr><tr><td>=</td></tr><tr><td>==</td></tr><tr><td>&gt;</td></tr><tr><td>&gt;=</td></tr><tr><td>^</td></tr><tr><td>abs</td></tr><tr><td>acos</td></tr><tr><td>add_months</td></tr><tr><td>and</td></tr><tr><td>approx_count_distinct</td></tr><tr><td>array</td></tr><tr><td>array_contains</td></tr><tr><td>ascii</td></tr><tr><td>asin</td></tr><tr><td>assert_true</td></tr><tr><td>atan</td></tr><tr><td>atan2</td></tr><tr><td>avg</td></tr><tr><td>base64</td></tr><tr><td>between</td></tr><tr><td>bigint</td></tr><tr><td>bin</td></tr><tr><td>binary</td></tr><tr><td>boolean</td></tr><tr><td>case</td></tr><tr><td>cbrt</td></tr><tr><td>ceil</td></tr><tr><td>ceiling</td></tr><tr><td>char</td></tr><tr><td>coalesce</td></tr><tr><td>collect_list</td></tr><tr><td>collect_set</td></tr><tr><td>compute_stats</td></tr><tr><td>concat</td></tr><tr><td>concat_ws</td></tr><tr><td>context_ngrams</td></tr><tr><td>conv</td></tr><tr><td>corr</td></tr><tr><td>cos</td></tr><tr><td>cosh</td></tr><tr><td>count</td></tr><tr><td>covar_pop</td></tr><tr><td>covar_samp</td></tr><tr><td>crc32</td></tr><tr><td>create_union</td></tr><tr><td>cume_dist</td></tr><tr><td>current_database</td></tr><tr><td>current_date</td></tr><tr><td>current_timestamp</td></tr><tr><td>current_user</td></tr><tr><td>date</td></tr><tr><td>date_add</td></tr><tr><td>date_format</td></tr><tr><td>date_sub</td></tr><tr><td>datediff</td></tr><tr><td>day</td></tr><tr><td>dayofmonth</td></tr><tr><td>dayofyear</td></tr><tr><td>decimal</td></tr><tr><td>decode</td></tr><tr><td>degrees</td></tr><tr><td>dense_rank</td></tr><tr><td>div</td></tr><tr><td>double</td></tr><tr><td>e</td></tr><tr><td>elt</td></tr><tr><td>encode</td></tr><tr><td>ewah_bitmap</td></tr><tr><td>ewah_bitmap_and</td></tr><tr><td>ewah_bitmap_empty</td></tr><tr><td>ewah_bitmap_or</td></tr><tr><td>exp</td></tr><tr><td>explode</td></tr><tr><td>expm1</td></tr><tr><td>factorial</td></tr><tr><td>field</td></tr><tr><td>find_in_set</td></tr><tr><td>first</td></tr><tr><td>first_value</td></tr><tr><td>float</td></tr><tr><td>floor</td></tr><tr><td>format_number</td></tr><tr><td>format_string</td></tr><tr><td>from_unixtime</td></tr><tr><td>from_utc_timestamp</td></tr><tr><td>get_json_object</td></tr><tr><td>greatest</td></tr><tr><td>hash</td></tr><tr><td>hex</td></tr><tr><td>histogram_numeric</td></tr><tr><td>hour</td></tr><tr><td>hypot</td></tr><tr><td>if</td></tr><tr><td>in</td></tr><tr><td>in_file</td></tr><tr><td>index</td></tr><tr><td>initcap</td></tr><tr><td>inline</td></tr><tr><td>input_file_name</td></tr><tr><td>instr</td></tr><tr><td>int</td></tr><tr><td>interval_day_time</td></tr><tr><td>interval_year_month</td></tr><tr><td>isnan</td></tr><tr><td>isnotnull</td></tr><tr><td>isnull</td></tr><tr><td>java_method</td></tr><tr><td>json_tuple</td></tr><tr><td>kurtosis</td></tr><tr><td>lag</td></tr><tr><td>last</td></tr><tr><td>last_day</td></tr><tr><td>last_value</td></tr><tr><td>lcase</td></tr><tr><td>lead</td></tr><tr><td>least</td></tr><tr><td>length</td></tr><tr><td>levenshtein</td></tr><tr><td>like</td></tr><tr><td>ln</td></tr><tr><td>locate</td></tr><tr><td>log</td></tr><tr><td>log10</td></tr><tr><td>log1p</td></tr><tr><td>log2</td></tr><tr><td>lower</td></tr><tr><td>lpad</td></tr><tr><td>ltrim</td></tr><tr><td>map</td></tr><tr><td>map_keys</td></tr><tr><td>map_values</td></tr><tr><td>matchpath</td></tr><tr><td>max</td></tr><tr><td>md5</td></tr><tr><td>mean</td></tr><tr><td>min</td></tr><tr><td>minute</td></tr><tr><td>monotonically_increasing_id</td></tr><tr><td>month</td></tr><tr><td>months_between</td></tr><tr><td>named_struct</td></tr><tr><td>nanvl</td></tr><tr><td>negative</td></tr><tr><td>next_day</td></tr><tr><td>ngrams</td></tr><tr><td>noop</td></tr><tr><td>noopstreaming</td></tr><tr><td>noopwithmap</td></tr><tr><td>noopwithmapstreaming</td></tr><tr><td>not</td></tr><tr><td>now</td></tr><tr><td>ntile</td></tr><tr><td>nvl</td></tr><tr><td>or</td></tr><tr><td>parse_url</td></tr><tr><td>parse_url_tuple</td></tr><tr><td>percent_rank</td></tr><tr><td>percentile</td></tr><tr><td>percentile_approx</td></tr><tr><td>pi</td></tr><tr><td>pmod</td></tr><tr><td>posexplode</td></tr><tr><td>positive</td></tr><tr><td>pow</td></tr><tr><td>power</td></tr><tr><td>printf</td></tr><tr><td>quarter</td></tr><tr><td>radians</td></tr><tr><td>rand</td></tr><tr><td>randn</td></tr><tr><td>rank</td></tr><tr><td>reflect</td></tr><tr><td>reflect2</td></tr><tr><td>regexp</td></tr><tr><td>regexp_extract</td></tr><tr><td>regexp_replace</td></tr><tr><td>repeat</td></tr><tr><td>reverse</td></tr><tr><td>rint</td></tr><tr><td>rlike</td></tr><tr><td>round</td></tr><tr><td>row_number</td></tr><tr><td>rpad</td></tr><tr><td>rtrim</td></tr><tr><td>second</td></tr><tr><td>sentences</td></tr><tr><td>sha</td></tr><tr><td>sha1</td></tr><tr><td>sha2</td></tr><tr><td>shiftleft</td></tr><tr><td>shiftright</td></tr><tr><td>shiftrightunsigned</td></tr><tr><td>sign</td></tr><tr><td>signum</td></tr><tr><td>sin</td></tr><tr><td>sinh</td></tr><tr><td>size</td></tr><tr><td>skewness</td></tr><tr><td>smallint</td></tr><tr><td>sort_array</td></tr><tr><td>soundex</td></tr><tr><td>space</td></tr><tr><td>spark_partition_id</td></tr><tr><td>split</td></tr><tr><td>sqrt</td></tr><tr><td>stack</td></tr><tr><td>std</td></tr><tr><td>stddev</td></tr><tr><td>stddev_pop</td></tr><tr><td>stddev_samp</td></tr><tr><td>str_to_map</td></tr><tr><td>string</td></tr><tr><td>struct</td></tr><tr><td>substr</td></tr><tr><td>substring</td></tr><tr><td>substring_index</td></tr><tr><td>sum</td></tr><tr><td>tan</td></tr><tr><td>tanh</td></tr><tr><td>timestamp</td></tr><tr><td>tinyint</td></tr><tr><td>to_date</td></tr><tr><td>to_unix_timestamp</td></tr><tr><td>to_utc_timestamp</td></tr><tr><td>translate</td></tr><tr><td>trim</td></tr><tr><td>trunc</td></tr><tr><td>ucase</td></tr><tr><td>unbase64</td></tr><tr><td>unhex</td></tr><tr><td>unix_timestamp</td></tr><tr><td>upper</td></tr><tr><td>var_pop</td></tr><tr><td>var_samp</td></tr><tr><td>varchar</td></tr><tr><td>variance</td></tr><tr><td>weekofyear</td></tr><tr><td>when</td></tr><tr><td>windowingtablefunction</td></tr><tr><td>xpath</td></tr><tr><td>xpath_boolean</td></tr><tr><td>xpath_double</td></tr><tr><td>xpath_float</td></tr><tr><td>xpath_int</td></tr><tr><td>xpath_long</td></tr><tr><td>xpath_number</td></tr><tr><td>xpath_short</td></tr><tr><td>xpath_string</td></tr><tr><td>year</td></tr><tr><td>|</td></tr><tr><td>~</td></tr></table>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql SHOW FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " `EXPLAIN` can be used to understand the Physical Plan of the SQL statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>plan</th></tr><tr><td>== Physical Plan ==</td></tr><tr><td>Sort [top_articles#321L DESC], true, 0</td></tr><tr><td>+- ConvertToUnsafe</td></tr><tr><td>   +- Exchange rangepartitioning(top_articles#321L DESC,200), None</td></tr><tr><td>      +- ConvertToSafe</td></tr><tr><td>         +- TungstenAggregate(key=[curr_title#4], functions=[(sum(cast(n#2 as bigint)),mode=Final,isDistinct=false)], output=[curr_title#4,top_articles#321L])</td></tr><tr><td>            +- TungstenExchange hashpartitioning(curr_title#4,200), None</td></tr><tr><td>               +- TungstenAggregate(key=[curr_title#4], functions=[(sum(cast(n#2 as bigint)),mode=Partial,isDistinct=false)], output=[curr_title#4,sum#346L])</td></tr><tr><td>                  +- InMemoryColumnarTableScan [curr_title#4,n#2], InMemoryRelation [prev_title#3,curr_title#4,n#2,type#5], true, 10000, StorageLevel(true, true, false, true, 1), ConvertToUnsafe, None</td></tr></table>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql EXPLAIN \n",
    "  SELECT curr_title, SUM(n) AS top_articles\n",
    "    FROM clickstream GROUP BY curr_title\n",
    "    ORDER BY top_articles DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Since Spark SQL is not designed to be a low-latency transactional database (like MySQL or Cassandra), INSERTs, UPDATEs and DELETEs are not supported. (Spark SQL is typically used for batch analysis of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Question #2:\n",
    "** Who sent the most traffic to Wikipedia in Feb 2015?** So, who were the top referers to Wikipedia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------+----------+\n",
      "|     prev_title|    sum(n)|\n",
      "+---------------+----------+\n",
      "|   other-google|1583172874|\n",
      "|    other-empty|1039020465|\n",
      "|other-wikipedia|  99610051|\n",
      "|          other|  83225546|\n",
      "|     other-bing|  64539160|\n",
      "|    other-yahoo|  49074812|\n",
      "|      Main_Page|  25077303|\n",
      "|  other-twitter|  22541757|\n",
      "| other-facebook|   2599787|\n",
      "|     Chris_Kyle|   1547364|\n",
      "+---------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF2\n",
    "  .groupBy(\"prev_title\")\n",
    "  .sum()\n",
    "  .orderBy($\"sum(n)\".desc)\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The top referer by a large margin is Google. Next comes refererless traffic (usually clients using HTTPS). The third largest sender of traffic to English Wikipedia are Wikipedia pages that are not in the main namespace (ns = 0) of English Wikipedia. Learn about the Wikipedia namespaces here:\n",
    "https://en.wikipedia.org/wiki/Wikipedia:Project_namespace\n",
    "\n",
    "Also, note that Twitter sends 10x more requests to Wikipedia than Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Question #3:\n",
    "** What were the top 5 trending articles on Twitter in Feb 2015?**\n",
    "\n",
    "** Challenge 2:** Can you answer this question using DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+----------------+------+\n",
      "|      curr_title|sum(n)|\n",
      "+----------------+------+\n",
      "| André_the_Giant|286710|\n",
      "|Harald_Bluetooth|258130|\n",
      "|    London_Stone|247418|\n",
      "|         Yaodong|184078|\n",
      "|    New_Horizons|174157|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Type in your answer here\n",
    "clickstreamDF2\n",
    "  .filter(\"prev_title = 'other-twitter'\")\n",
    "  .groupBy(\"curr_title\")\n",
    "  .sum()\n",
    "  .orderBy($\"sum(n)\".desc)\n",
    "  .limit(5).show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ** Challenge 3:** Try re-writing the query above using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>curr_title</th><th>top_twitter</th></tr><tr><td>André_the_Giant</td><td>286710</td></tr><tr><td>Harald_Bluetooth</td><td>258130</td></tr><tr><td>London_Stone</td><td>247418</td></tr><tr><td>Yaodong</td><td>184078</td></tr><tr><td>New_Horizons</td><td>174157</td></tr></table>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql SELECT curr_title, SUM(n) AS top_twitter FROM clickstream\n",
    "WHERE prev_title = 'other-twitter'\n",
    "GROUP BY curr_title\n",
    "ORDER BY top_twitter DESC LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Question #4:\n",
    "** What are the most requested missing pages? ** (These are the articles that someone should create on Wikipedia!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The type column of our table has 3 possible values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+----+\n",
      "|type|\n",
      "+----+\n",
      "|null|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"SELECT DISTINCT type FROM clickstream\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " These are described as:\n",
    "  - **link** - if the referer and request are both articles and the referer links to the request\n",
    "  - **redlink** - if the referer is an article and links to the request, but the request is not in the production enwiki.page table\n",
    "  - **other** - if the referer and request are both articles but the referer does not link to the request. This can happen when clients search or spoof their refer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Redlinks are links to a Wikipedia page that does not exist, either because it has been deleted, or because the author is anticipating the creation of the page. Seeing which redlinks are the most viewed is interesting because it gives some indication about demand for missing content.\n",
    "\n",
    "Let's find the most popular redlinks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|curr_title|sum(n)|\n",
      "+----------+------+\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF2.filter(\"type = 'redlink'\").groupBy(\"curr_title\").sum().orderBy($\"sum(n)\".desc).limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Indeed there doesn't appear to be an article on the Russian actress [Anna Lezhneva](https://en.wikipedia.org/wiki/Anna_Lezhneva) on Wikipedia. Maybe you should create it!\n",
    "\n",
    "Note that if you clicked on the link for Anna Lezhneva in this cell, then you registered another Redlink for her article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Question #5:\n",
    "** What does the traffic inflow vs outflow look like for the most requested pages? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Wikipedia users get to their desired article by either searching for the article in a search engine or navigating from one Wikipedia article to another by following a link. For example, depending on which technique a user used to get to his desired article of **San Francisco**, the (`prev_title`, `curr_title`) tuples would look like:\n",
    "- (`other-google`, `San_Francisco`)\n",
    "or\n",
    "- (`Berkeley`, `San_Francisco`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Lets look at the ratio of incoming to outgoing links for the most requested pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " First, find the pageviews per article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------------+--------+\n",
      "|          curr_title|in_count|\n",
      "+--------------------+--------+\n",
      "|Celaenorrhinus_le...|      16|\n",
      "|            Cellulin|      22|\n",
      "|Cementerio_Católi...|      20|\n",
      "|Centaurs_in_popul...|     392|\n",
      "|Centennial_Challe...|     389|\n",
      "|Center_for_the_St...|      85|\n",
      "|Central_Avenue_Hi...|      33|\n",
      "|Central_Baptist_T...|     103|\n",
      "|Central_Counterpa...|    3061|\n",
      "|Central_High_Scho...|     169|\n",
      "+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val pageviewsPerArticleDF = clickstreamDF2\n",
    "  .groupBy(\"curr_title\")\n",
    "  .sum(\n",
    "  ).withColumnRenamed(\"sum(n)\", \"in_count\")\n",
    "\n",
    "\n",
    "pageviewsPerArticleDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Above we can see that the `.17_Remington` article on Wikipedia in Feb 2015, got 2,143 views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Then, find the link clicks per article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------------+---------+\n",
      "|          prev_title|out_count|\n",
      "+--------------------+---------+\n",
      "|Robins_Air_Force_...|      574|\n",
      "|     Resident_Evil_4|     9178|\n",
      "|No_Strings_Attach...|     2230|\n",
      "|        Tawny_Kitaen|     3783|\n",
      "| Master_(Doctor_Who)|    15501|\n",
      "|        Folding@home|     1205|\n",
      "|    Mersenne_twister|     2236|\n",
      "|          Plant_cell|     3680|\n",
      "|Electron_transpor...|     3083|\n",
      "|           Ecosystem|    11667|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val linkclicksPerArticleDF = clickstreamDF2\n",
    "  .groupBy(\"prev_title\")\n",
    "  .sum()\n",
    "  .withColumnRenamed(\"sum(n)\", \"out_count\")\n",
    "\n",
    "\n",
    "linkclicksPerArticleDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " So, when people went to the `David_Janson` article on Wikipedia in Feb 2015, 340 times they clicked on a link in that article to go to a next article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Join the two DataFrames we just created to get a wholistic picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------------+---------+--------------------+---------+\n",
      "|          curr_title| in_count|          prev_title|out_count|\n",
      "+--------------------+---------+--------------------+---------+\n",
      "|           Main_Page|489603866|           Main_Page| 25077303|\n",
      "|          Chris_Kyle|  4211238|          Chris_Kyle|  1547364|\n",
      "|             Malware|  4067814|             Malware|    10111|\n",
      "|       Charlie_Hebdo|  2581856|       Charlie_Hebdo|   413185|\n",
      "|     Leptin_receptor|  2565856|     Leptin_receptor|      118|\n",
      "|              Chrome|  1792151|              Chrome|     6096|\n",
      "|       Script_kiddie|  1779860|       Script_kiddie|     2066|\n",
      "|American_Sniper_(...|  1753218|American_Sniper_(...|  1085765|\n",
      "|Winston-Salem/For...|  1542559|Winston-Salem/For...|      188|\n",
      "|        Flow_control|  1369143|        Flow_control|     1008|\n",
      "+--------------------+---------+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val in_outDF = pageviewsPerArticleDF\n",
    "    .join(linkclicksPerArticleDF, ($\"curr_title\" === $\"prev_title\"))\n",
    "    .orderBy($\"in_count\".desc)\n",
    "\n",
    "in_outDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The `curr_title` and `prev_title` above are the same, so we can just display one of them in the future. Next, add a new `ratio` column to easily see whether there is more `in_count` or `out_count` for an article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------+---------+---------+--------------------+\n",
      "|     curr_title| in_count|out_count|               ratio|\n",
      "+---------------+---------+---------+--------------------+\n",
      "|      Main_Page|489603866| 25077303|0.051219577175479244|\n",
      "|     Chris_Kyle|  4211238|  1547364|   0.367436843987445|\n",
      "|        Malware|  4067814|    10111|0.002485610207349697|\n",
      "|  Charlie_Hebdo|  2581856|   413185| 0.16003409950051437|\n",
      "|Leptin_receptor|  2565856|      118|4.598855118915481E-5|\n",
      "+---------------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val in_out_ratioDF = in_outDF.withColumn(\"ratio\", $\"out_count\" / $\"in_count\").cache()\n",
    "\n",
    "in_out_ratioDF.select($\"curr_title\", $\"in_count\", $\"out_count\", $\"ratio\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " We can see above that when clients went to the **Alive** article, almost nobody clicked any links in the article to go on to another article.\n",
    "\n",
    "But 49% of people who visited the **Fifty Shades of Grey** article clicked on a link in the article and continued to browse Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Question #6:\n",
    "** What does the traffic flow pattern look like for the \"San Francisco\" article? Create a visualization for this. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+-------------+--------+-------------+---------+------------------+\n",
      "|   curr_title|in_count|   prev_title|out_count|             ratio|\n",
      "+-------------+--------+-------------+---------+------------------+\n",
      "|San_Francisco|  146200|San_Francisco|    45930|0.3141586867305062|\n",
      "+-------------+--------+-------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_out_ratioDF.filter(\"curr_title = 'San_Francisco'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Hmm, so about 41% of clients who visit the San_Francisco page, click on through to another article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Which referrers send the most traffic to the \"San Francisco\" article?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>prev_title</th><th>curr_title</th><th>n</th><th>type</th></tr><tr><td>other-google</td><td>San_Francisco</td><td>56493</td><td>null</td></tr><tr><td>other-empty</td><td>San_Francisco</td><td>50011</td><td>null</td></tr><tr><td>other-wikipedia</td><td>San_Francisco</td><td>7645</td><td>null</td></tr><tr><td>other</td><td>San_Francisco</td><td>2718</td><td>null</td></tr><tr><td>other-bing</td><td>San_Francisco</td><td>2291</td><td>null</td></tr><tr><td>Main_Page</td><td>San_Francisco</td><td>2272</td><td>null</td></tr><tr><td>other-yahoo</td><td>San_Francisco</td><td>1587</td><td>null</td></tr><tr><td>Pornhub</td><td>San_Francisco</td><td>1247</td><td>null</td></tr><tr><td>San_Francisco_Bay_Area</td><td>San_Francisco</td><td>1170</td><td>null</td></tr><tr><td>List_of_United_States_cities_by_population</td><td>San_Francisco</td><td>1065</td><td>null</td></tr></table>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql SELECT * FROM clickstream\n",
    "    WHERE curr_title LIKE 'San_Francisco'\n",
    "    ORDER BY n DESC LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Here's the same query using DataFrames and `show()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+--------------------+-------------+-----+----+\n",
      "|          prev_title|   curr_title|    n|type|\n",
      "+--------------------+-------------+-----+----+\n",
      "|        other-google|San_Francisco|56493|null|\n",
      "|         other-empty|San_Francisco|50011|null|\n",
      "|     other-wikipedia|San_Francisco| 7645|null|\n",
      "|               other|San_Francisco| 2718|null|\n",
      "|          other-bing|San_Francisco| 2291|null|\n",
      "|           Main_Page|San_Francisco| 2272|null|\n",
      "|         other-yahoo|San_Francisco| 1587|null|\n",
      "|             Pornhub|San_Francisco| 1247|null|\n",
      "|San_Francisco_Bay...|San_Francisco| 1170|null|\n",
      "|List_of_United_St...|San_Francisco| 1065|null|\n",
      "+--------------------+-------------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clickstreamDF2.filter($\"curr_title\".rlike(\"\"\"^San_Francisco$\"\"\")).orderBy($\"n\".desc).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ** Challenge 4:** Which future articles does the San_Francisco article send most traffic onward to? Try writing this query using the DataFrames API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+-------------+--------------------+----+----+\n",
      "|   prev_title|          curr_title|   n|type|\n",
      "+-------------+--------------------+----+----+\n",
      "|San_Francisco|List_of_people_fr...|1600|null|\n",
      "|San_Francisco|  Golden_Gate_Bridge|1472|null|\n",
      "|San_Francisco|          California|1152|null|\n",
      "|San_Francisco|         Los_Angeles| 913|null|\n",
      "|San_Francisco|Transamerica_Pyramid| 840|null|\n",
      "|San_Francisco|1906_San_Francisc...| 833|null|\n",
      "|San_Francisco|Neighborhoods_in_...| 824|null|\n",
      "|San_Francisco| Ed_Lee_(politician)| 750|null|\n",
      "|San_Francisco|     Alcatraz_Island| 727|null|\n",
      "|San_Francisco|San_Jose,_California| 651|null|\n",
      "|San_Francisco| Northern_California| 632|null|\n",
      "|San_Francisco|San_Francisco_Bay...| 596|null|\n",
      "|San_Francisco|San_Francisco_(di...| 569|null|\n",
      "|San_Francisco|           San_Diego| 553|null|\n",
      "|San_Francisco|Chinatown,_San_Fr...| 552|null|\n",
      "|San_Francisco|San_Francisco_Int...| 520|null|\n",
      "|San_Francisco|Lombard_Street_(S...| 512|null|\n",
      "|San_Francisco|List_of_United_St...| 482|null|\n",
      "|San_Francisco|San_Jose-San_Fran...| 480|null|\n",
      "|San_Francisco| California_Republic| 458|null|\n",
      "+-------------+--------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Type in your answer here...\n",
    "clickstreamDF2.filter($\"prev_title\".rlike(\"\"\"^San_Francisco$\"\"\")).orderBy($\"n\".desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Above we can see the topics most people are interested in, when they get to the San_Francisco article. The [Golden_Gate_Bridge](https://en.wikipedia.org/wiki/Golden_Gate_Bridge) is the second most clicked on link in the San_Francisco article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Finally, we'll use a Google Visualization library to create a Sankey diagram. Sankey diagrams are a flow diagram, in which the width of the arrows are shown proportionally to the flow quantify traffic:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The chart above shows how people get to a Wikipedia article and what articles they click on next.\n",
    "\n",
    "This diagram shows incoming and outgoing traffic to the \"San Francisco\" article. We can see that most people found the \"San Francisco\" page through Google search and only a small fraction of the readers went on to another article (most went on to the \"List of people in San Francisco\" article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Note that it is also possible to programmatically add in the values in the HTML, so you don't have to hand-code it. But to keep things simple, we've hand coded it above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Bonus:\n",
    "** Learning about Explain to understand Catalyst internals **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " The `explain()` method can be called on a DataFrame to understand its physical plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "InMemoryColumnarTableScan [curr_title#4,in_count#465L,prev_title#3,out_count#490L,ratio#556], InMemoryRelation [curr_title#4,in_count#465L,prev_title#3,out_count#490L,ratio#556], true, 10000, StorageLevel(true, true, false, true, 1), Sort [in_count#465L DESC], true, 0, None\n"
     ]
    }
   ],
   "source": [
    "in_out_ratioDF.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " You can also pass in `true` to see the logical & physical plans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*,('out_count / 'in_count) AS ratio#556]\n",
      "+- Sort [in_count#465L DESC], true\n",
      "   +- Join Inner, Some((curr_title#4 = prev_title#3))\n",
      "      :- Project [curr_title#4,sum(n)#464L AS in_count#465L]\n",
      "      :  +- Aggregate [curr_title#4], [curr_title#4,(sum(cast(n#2 as bigint)),mode=Complete,isDistinct=false) AS sum(n)#464L]\n",
      "      :     +- Project [prev_title#3,curr_title#4,n#2,type#5]\n",
      "      :        +- Relation[prev_id#0,curr_id#1,n#2,prev_title#3,curr_title#4,type#5] CsvRelation(<function0>,Some(file:///mnt/ephemeral/summitdata/2015_01_clickstream.tsv),true,\t,\",null,#,PERMISSIVE,COMMONS,false,false,false,null,true,null)\n",
      "      +- Project [prev_title#3,sum(n)#489L AS out_count#490L]\n",
      "         +- Aggregate [prev_title#3], [prev_title#3,(sum(cast(n#2 as bigint)),mode=Complete,isDistinct=false) AS sum(n)#489L]\n",
      "            +- Project [prev_title#3,curr_title#4,n#2,type#5]\n",
      "               +- Relation[prev_id#0,curr_id#1,n#2,prev_title#3,curr_title#4,type#5] CsvRelation(<function0>,Some(file:///mnt/ephemeral/summitdata/2015_01_clickstream.tsv),true,\t,\",null,#,PERMISSIVE,COMMONS,false,false,false,null,true,null)\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "curr_title: string, in_count: bigint, prev_title: string, out_count: bigint, ratio: double\n",
      "Project [curr_title#4,in_count#465L,prev_title#3,out_count#490L,(cast(out_count#490L as double) / cast(in_count#465L as double)) AS ratio#556]\n",
      "+- Sort [in_count#465L DESC], true\n",
      "   +- Join Inner, Some((curr_title#4 = prev_title#3))\n",
      "      :- Project [curr_title#4,sum(n)#464L AS in_count#465L]\n",
      "      :  +- Aggregate [curr_title#4], [curr_title#4,(sum(cast(n#2 as bigint)),mode=Complete,isDistinct=false) AS sum(n)#464L]\n",
      "      :     +- Project [prev_title#3,curr_title#4,n#2,type#5]\n",
      "      :        +- Relation[prev_id#0,curr_id#1,n#2,prev_title#3,curr_title#4,type#5] CsvRelation(<function0>,Some(file:///mnt/ephemeral/summitdata/2015_01_clickstream.tsv),true,\t,\",null,#,PERMISSIVE,COMMONS,false,false,false,null,true,null)\n",
      "      +- Project [prev_title#3,sum(n)#489L AS out_count#490L]\n",
      "         +- Aggregate [prev_title#3], [prev_title#3,(sum(cast(n#2 as bigint)),mode=Complete,isDistinct=false) AS sum(n)#489L]\n",
      "            +- Project [prev_title#3,curr_title#4,n#2,type#5]\n",
      "               +- Relation[prev_id#0,curr_id#1,n#2,prev_title#3,curr_title#4,type#5] CsvRelation(<function0>,Some(file:///mnt/ephemeral/summitdata/2015_01_clickstream.tsv),true,\t,\",null,#,PERMISSIVE,COMMONS,false,false,false,null,true,null)\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "InMemoryRelation [curr_title#4,in_count#465L,prev_title#3,out_count#490L,ratio#556], true, 10000, StorageLevel(true, true, false, true, 1), Sort [in_count#465L DESC], true, 0, None\n",
      "\n",
      "== Physical Plan ==\n",
      "InMemoryColumnarTableScan [curr_title#4,in_count#465L,prev_title#3,out_count#490L,ratio#556], InMemoryRelation [curr_title#4,in_count#465L,prev_title#3,out_count#490L,ratio#556], true, 10000, StorageLevel(true, true, false, true, 1), Sort [in_count#465L DESC], true, 0, None\n"
     ]
    }
   ],
   "source": [
    "in_out_ratioDF.explain(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " This concludes the Clickstream lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " \n",
    "### Homework:\n",
    "** Recreate the same visualization above, but instead of the \"San Francisco\" article, choose another topic you care about (maybe `Apache_Spark`?).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ###Post lab demos below:\n",
    "\n",
    "This section will be covered by the instructor using a hands-on demo shortly..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Which pages multiplied input clicks the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clickstreamDF2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val inClicksDF = clickstreamDF2\n",
    "  .groupBy($\"curr_title\")\n",
    "  .sum()\n",
    "  .withColumnRenamed(\"sum(n)\", \"in_clicks\")\n",
    "  .select($\"curr_title\", $\"in_clicks\")\n",
    "  .as(\"in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inClicksDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val outClicksDF = clickstreamDF2\n",
    "\t.filter($\"type\" === \"link\")\n",
    "\t.groupBy($\"prev_title\")\n",
    "\t.sum()\n",
    "\t.withColumnRenamed(\"sum(n)\", \"out_clicks\")\n",
    "\t.select($\"prev_title\", $\"out_clicks\")\n",
    "\t.as(\"out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outClicksDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Notes...Mention that the filter is good, removes 50% of data\n",
    "Then Aggregate? partial aggregation, dont? worry about details\n",
    "then shuffle\n",
    "then reduce side aggregation\n",
    "Cartesian Product: very expensive? joining every single row on left to rows on right? takes forever\n",
    "Get?s triggered by UDF.. during join, we?re passing in an arbitrary function.. so the user can do whatever they want in the function?\n",
    "but take a closer look at the body of the UDF above (title1.toLowercase == title2.toLowerCase, you can see that we?re just doing a simple eqality check\n",
    "b/c it?s an arbitrary UDF, Catalyst (SQL query optimizer) doesn?t know how to optimize this join b/c it doesn?t understand it.. it?s opaque\n",
    "Solution: a better UDF, here we explicitly use the built in Spark SQL equality expression that Catalyst does understand. I?m still using a UDF to convert to lowercase, just not for equality\n",
    "Now verify CP is gone in UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Define a UDF for comparing article titles\n",
    "val compareUDF = udf((title1: String, title2: String) => title1.toLowerCase == title2.toLowerCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "// STEVE: This join will take long - don't run it. 40000 tasks. And will OOM\n",
    "\n",
    "// Join these 2 DFs to find the (output clicks) / (input clicks) factor\n",
    "val joinedDF = outClicksDF\n",
    "\t.join(inClicksDF, compareUDF($\"in.curr_title\", $\"out.prev_title\"))\n",
    "\t.withColumn(\"multiplication_factor\", $\"out_clicks\" / $\"in_clicks\")\n",
    "\t.select($\"in.curr_title\", $\"in_clicks\", $\"out_clicks\", $\"multiplication_factor\")\n",
    "\n",
    "joinedDF.orderBy($\"multiplication_factor\".desc).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Define a UDF for comparing article titles\n",
    "val formatUDF = udf((title1: String) => title1.toLowerCase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Fixed performance issue\n",
    "val joinedDF = outClicksDF\n",
    "\t.join(inClicksDF, formatUDF($\"in.curr_title\") === formatUDF($\"out.prev_title\"))\n",
    "\t.withColumn(\"multiplication_factor\", $\"out_clicks\" / $\"in_clicks\")\n",
    "\t.select($\"in.curr_title\", $\"in_clicks\", $\"out_clicks\", $\"multiplication_factor\")\n",
    "\n",
    "joinedDF.orderBy($\"multiplication_factor\".desc).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Fixed performance issue\n",
    "val joinedDF2 = outClicksDF\n",
    "\t.join(inClicksDF, formatUDF($\"in.curr_title\") === formatUDF($\"out.prev_title\"))\n",
    "\t.withColumn(\"multiplication_factor\", $\"out_clicks\" / $\"in_clicks\")\n",
    "\t.select($\"in.curr_title\", $\"in_clicks\", $\"out_clicks\", $\"multiplication_factor\")\n",
    "\n",
    "joinedDF2.orderBy($\"multiplication_factor\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Interesting, looks like mostly cities, tech and colors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
