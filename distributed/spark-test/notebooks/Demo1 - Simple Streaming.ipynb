{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "// Databricks notebook source exported at Wed, 17 Feb 2016 20:50:15 UTC\n",
    " #### Business question:\n",
    "\n",
    "* Question # 1) How many Edits occur every 3 seconds to the English Wikipedia vs. another language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.storage._\n",
    "import org.apache.spark.streaming._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// The batch interval sets how we collect data for, before analyzing it in a batch\n",
    "val BatchInterval = Seconds(3)\n",
    "\n",
    "// We'll use a unique server for the English edit stream\n",
    "val EnglishStreamingServerHost  = \"52.89.53.194\"\n",
    "val EnglishStreamingServerPort  = 9002 //en\n",
    "\n",
    "// We'll use a unique server for all the other language edit streams\n",
    "val MiscLangStreamingServerHost  = \"54.68.10.240\"\n",
    "\n",
    "val SpanishStreamingServerPort  = 9007 //es\n",
    "val GermanStreamingServerPort  = 9003 //de\n",
    "val FrenchStreamingServerPort  = 9004 //fr\n",
    "val RussianStreamingServerPort  = 9005 //ru\n",
    "val ItalianStreamingServerPort  = 9006 //it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext = org.apache.spark.SparkContext@74babce8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Create a new `StreamingContext`, using the SparkContext and batch interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val ssc = new StreamingContext(sc, BatchInterval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Create two DStreams, one for English and another for a language of your choosing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val baseEnDSTREAM = ssc.socketTextStream(EnglishStreamingServerHost, EnglishStreamingServerPort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val baseDeDSTREAM = ssc.socketTextStream(MiscLangStreamingServerHost, GermanStreamingServerPort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " For each DStream, parse the incoming JSON and register a new temporary table every batch interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Create an English temp table at every 3 sec batch interval\n",
    "baseEnDSTREAM.foreachRDD { rdd =>\n",
    "  if(! rdd.isEmpty) {\n",
    "    sqlContext.read.json(rdd).registerTempTable(\"English_Edits\")\n",
    "  }\n",
    "}\n",
    "\n",
    "  baseDeDSTREAM.foreachRDD { rdd => \n",
    "    \n",
    "    if (! rdd.isEmpty) {\n",
    "      sqlContext.read.json(rdd).registerTempTable(\"German_Edits\")\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  ssc.remember(Minutes(1))  // To make sure data is not deleted by the time we query it interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssc.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from English_Edits\").count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "[User:Masterknighted/sandbox]\n",
      "[Category:Pages with reference errors]\n",
      "[Category:CS1 maint: Explicit use of et al.]\n",
      "[Category:Pages with reference errors]\n",
      "[Category:Atchison, Topeka and Santa Fe Railway stations in San Bernardino County, California]\n",
      "[Category:Atchison, Topeka and Santa Fe Railway stations]\n",
      "[Special:Log/thanks]\n",
      "[Citizenship in the United States]\n",
      "[DaVarryl Williamson]\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select page from English_Edits\").collect foreach println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from German_Edits\").count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anonymous: boolean (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- comment: string (nullable = true)\n",
      " |-- delta: long (nullable = true)\n",
      " |-- flag: string (nullable = true)\n",
      " |-- namespace: string (nullable = true)\n",
      " |-- newPage: boolean (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- pageUrl: string (nullable = true)\n",
      " |-- robot: boolean (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- unpatrolled: boolean (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- userUrl: string (nullable = true)\n",
      " |-- wikipedia: string (nullable = true)\n",
      " |-- wikipediaLong: string (nullable = true)\n",
      " |-- wikipediaShort: string (nullable = true)\n",
      " |-- wikipediaUrl: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from English_Edits\").printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steve: not sure what this does.  there is a count(*) with no group by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\"SELECT first(channel) AS Language, Count(*) AS Edit_Count FROM English_Edits\n",
    "UNION\n",
    "SELECT first(channel) AS Language, Count(*)  AS Edit_Count FROM German_Edits\"\"\"\"\"\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----+\n",
      "|language|          timestamp|count|\n",
      "+--------+-------------------+-----+\n",
      "| english|2016-02-17T23:35:05|    1|\n",
      "| english|2016-02-17T23:35:05|    1|\n",
      "| english|2016-02-17T23:35:05|    1|\n",
      "| english|2016-02-17T23:35:05|    1|\n",
      "|  german|2016-02-17T23:35:04|    1|\n",
      "+--------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\" \n",
    "select \"english\" AS language, substring(timestamp, 0, 19) as timestamp, count(*) AS count from English_Edits GROUP BY timestamp UNION ALL\n",
    "select \"german\" AS language, substring(timestamp, 0, 19) as timestamp, count(*) AS count from German_Edits GROUP BY timestamp\"\"\").show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// Optional just to stop\n",
    "StreamingContext.getActive.foreach { _.stop(stopSparkContext = false) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
