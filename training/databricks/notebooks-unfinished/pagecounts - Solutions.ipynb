{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "// Databricks notebook source exported at Sun, 21 Feb 2016 05:11:43 UTC\n",
    " ### Solutions to pagecounts RDD and Datasets RunMe lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Answer to Challenge 1\n",
    "\n",
    "// gzip is an unsplittable compression format released in 1992. Therefore to uncompress a gzip file, it has to be read entirely in one machine and uncompressed together. It is not possible to parallelize this, so Spark ends up using just one task to read the file. bzip2, LZO and Snappy are  are examples of splittable compression formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " **Solutions to Question #2: ** How many requests total did English Wikipedia get in the past hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Answer to Challenge 2\n",
    "// Can you figure out how to yank out just the requests column and then sum all of the requests?\n",
    "\n",
    "// Yank out just the requests column\n",
    "enPagecountsRDD.map(x => x._3).take(5)\n",
    "\n",
    "// Then build upon that by summing up all of the requests\n",
    "enPagecountsRDD.map(x => x._3).sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Answer to Challenge 3\n",
    "// Implement this new strategy of collecting the data on the Driver for the summation.\n",
    "\n",
    "enPagecountsDS.map(x => x._3).collect.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Answer to Challenge 4\n",
    "// See if you can start with the `enPagecountsDS` Dataset, run a map on it like above, then convert it to a Dataframe and sum the `value` column.\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "enPagecountsDS \n",
    "  .map(x => x._3)\n",
    "  .toDF\n",
    "  .select(sum($\"value\"))\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " **Solutions to Question #3: **\n",
    "How many requests total did each Wikipedia project get total during this hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// Answer to Challenge 5\n",
    "/*First, we'll create key/value pairs from the project prefix and the number of requests, so we want to see results like: `((en, 3), (en.b, 2), (aa, 2), (en, 7))`. Can you use a map operation to get an RDD back with just k/v pairs?\n",
    "*/\n",
    "\n",
    "pagecounts4PartitionsRDD\n",
    "  .map(line => (line._1, line._3))\n",
    "  .take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " **Solutions to Question #4: **\n",
    "How many requests did the \"Apache Spark\" article recieve during this hour? Which Wikipedia language got the most requests for \"Apache Spark\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Answer to Challenge 6\n",
    "// Can you figure out which language edition of the Apache Spark page got the most hits? \n",
    "//Hint: Consider using a .map() after the filter() in the cell above.\n",
    "\n",
    "pagecountObjectsRDD\n",
    "  .filter(_.title.contains(\"Apache_Spark\"))\n",
    "  .map(x => (x.project, x.requests))\n",
    "  .collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  **Solutions to Question #5: **\n",
    "How many requests did the English Wiktionary project get during the captured hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Answer to Challenge 7\n",
    "pagecountObjectsRDD\n",
    "  .filter(_.project.contains(\"en.d\"))\n",
    "  .count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "  **Solutions to Question #6: **\n",
    "Which Apache project in English Wikipedia got the most hits during the captured hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
