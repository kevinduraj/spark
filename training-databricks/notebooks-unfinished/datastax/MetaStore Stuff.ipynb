{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.hive.HiveContext = org.apache.spark.sql.hive.HiveContext@16af0251"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|result|\n",
      "+------+\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"use stock\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|          tableName|isTemporary|\n",
      "+-------------------+-----------+\n",
      "|trades_by_tickerday|      false|\n",
      "+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"show tables\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN  2016-02-17 01:50:16,168 org.apache.hadoop.hive.serde2.lazy.LazyStruct: Extra bytes detected at the end of the row! Ignoring similar problems.\n",
      "[# col_name            \tdata_type           \tcomment             ]\n",
      "[\t \t ]\n",
      "[stock_symbol        \tstring              \tfrom deserializer   ]\n",
      "[day                 \tstring              \tfrom deserializer   ]\n",
      "[trade_timestamp     \tstring              \tfrom deserializer   ]\n",
      "[trade_id            \tint                 \tfrom deserializer   ]\n",
      "[exchange            \tstring              \tfrom deserializer   ]\n",
      "[price               \tfloat               \tfrom deserializer   ]\n",
      "[quantity            \tint                 \tfrom deserializer   ]\n",
      "[\t \t ]\n",
      "[# Detailed Table Information\t \t ]\n",
      "[Database:           \tstock               \t ]\n",
      "[Owner:              \troot                \t ]\n",
      "[CreateTime:         \tWed Feb 17 01:17:54 UTC 2016\t ]\n",
      "[LastAccessTime:     \tUNKNOWN             \t ]\n",
      "[Protect Mode:       \tNone                \t ]\n",
      "[Retention:          \t0                   \t ]\n",
      "[Location:           \tcfs://172.31.21.208/user/spark/warehouse/stock.db/trades_by_tickerday\t ]\n",
      "[Table Type:         \tEXTERNAL_TABLE      \t ]\n",
      "[Table Parameters:\t \t ]\n",
      "[\tEXTERNAL            \tTRUE                ]\n",
      "[\tauto_created        \ttrue                ]\n",
      "[\tcassandra.partitioner\torg.apache.cassandra.dht.Murmur3Partitioner]\n",
      "[\tspark.sql.sources.provider\torg.apache.spark.sql.cassandra]\n",
      "[\t \t ]\n",
      "[# Storage Information\t \t ]\n",
      "[SerDe Library:      \torg.apache.hadoop.hive.cassandra.cql3.serde.CqlColumnSerDe\t ]\n",
      "[InputFormat:        \torg.apache.hadoop.hive.cassandra.cql3.input.HiveCqlInputFormat\t ]\n",
      "[OutputFormat:       \torg.apache.hadoop.hive.cassandra.cql3.output.HiveCqlOutputFormat\t ]\n",
      "[Compressed:         \tNo                  \t ]\n",
      "[Num Buckets:        \t0                   \t ]\n",
      "[Bucket Columns:     \t[]                  \t ]\n",
      "[Sort Columns:       \t[]                  \t ]\n",
      "[Storage Desc Params:\t \t ]\n",
      "[\tkeyspace            \tstock               ]\n",
      "[\tpushdown            \ttrue                ]\n",
      "[\ttable               \ttrades_by_tickerday ]\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"describe formatted trades_by_tickerday\").collect foreach println"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String = CREATE EXTERNAL TABLE `trades_by_tickerday`(\n",
       "  `stock_symbol` string COMMENT 'from deserializer', \n",
       "  `day` string COMMENT 'from deserializer', \n",
       "  `trade_timestamp` string COMMENT 'from deserializer', \n",
       "  `trade_id` int COMMENT 'from deserializer', \n",
       "  `exchange` string COMMENT 'from deserializer', \n",
       "  `price` float COMMENT 'from deserializer', \n",
       "  `quantity` int COMMENT 'from deserializer')\n",
       "ROW FORMAT SERDE \n",
       "  'org.apache.hadoop.hive.cassandra.cql3.serde.CqlColumnSerDe' \n",
       "WITH SERDEPROPERTIES ( \n",
       "  'keyspace'='stock', \n",
       "  'pushdown'='true', \n",
       "  'table'='trades_by_tickerday') \n",
       "STORED AS INPUTFORMAT \n",
       "  'org.apache.hadoop.hive.cassandra.cql3.input.HiveCqlInputFormat' \n",
       "OUTPUTFORMAT \n",
       "  'org.apache.hadoop.hive.cassandra.cql3.output.HiveCqlOutputFormat'\n",
       "LOCATION\n",
       "  'cfs://172.31.21.208..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"show create table trades_by_tickerday\").collect.map(_.get(0)).mkString(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias(*)]\n",
      "+- 'UnresolvedRelation `trades_by_tickerday`, None\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "stock_symbol: string, day: string, trade_timestamp: string, trade_id: int, exchange: string, price: float, quantity: int\n",
      "Project [stock_symbol#37,day#38,trade_timestamp#39,trade_id#40,exchange#41,price#42,quantity#43]\n",
      "+- Subquery trades_by_tickerday\n",
      "   +- Relation[stock_symbol#37,day#38,trade_timestamp#39,trade_id#40,exchange#41,price#42,quantity#43] org.apache.spark.sql.cassandra.CassandraSourceRelation@229704bc\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [stock_symbol#37,day#38,trade_timestamp#39,trade_id#40,exchange#41,price#42,quantity#43]\n",
      "+- Relation[stock_symbol#37,day#38,trade_timestamp#39,trade_id#40,exchange#41,price#42,quantity#43] org.apache.spark.sql.cassandra.CassandraSourceRelation@229704bc\n",
      "\n",
      "== Physical Plan ==\n",
      "Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@229704bc[stock_symbol#37,day#38,trade_timestamp#39,trade_id#40,exchange#41,price#42,quantity#43]\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from trades_by_tickerday\").explain(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Local",
   "language": "scala",
   "name": "spark-dse-local"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
