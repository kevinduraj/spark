{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import the pagereads file in C*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cql create KEYSPACE if not exists databricks WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cql create table databricks.pagecounts (project text,\n",
    "                                          title text,\n",
    "                                          requests int,\n",
    "                                          size bigint,\n",
    "                                          primary key(project,title));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr></tr></table>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val schema = StructType(Seq(\n",
    "    StructField(\"project\", StringType, true),\n",
    "    StructField(\"title\", StringType, true),\n",
    "    StructField(\"requests\", IntegerType, true),\n",
    "    StructField(\"size\", LongType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rawFile = sqlContext.read.format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"false\")\n",
    "  .option(\"delimiter\", \" \")\n",
    "  .option(\"mode\", \"DROPMALFORMED\")\n",
    "  .schema(schema)\n",
    "  .load(\"file:///mnt/ephemeral/summitdata/pagecounts-20160210-180000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- project: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- requests: integer (nullable = true)\n",
      " |-- size: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawFile.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.Row = [aa,Category:Translators_deu-epo,1,4792]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawFile.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawFile.write.format(\"org.apache.spark.sql.cassandra\").\n",
    "options(Map(\"keyspace\" -> \"databricks\", \"table\" -> \"pagecounts\" )).\n",
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-DSE Cluster",
   "language": "scala",
   "name": "spark-dse-cluster"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
